{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree is like a flow chart with decision, arrow and terminal. The terminal is the class for classification and predicted value for regression. \n",
    "<img src=\"img/decision_tree.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One key for the decision tree is how to decide a good split point. With a good split, the groups after sjplitting should have small intra-differnce and relative large inter-difference.\n",
    "Here is one index named *entropy* to measure the randomness of data.\n",
    "$$H(x)=-\\Sigma_{i}^{n}P(x_i)\\text{log}_{2}P(x_i)$$\n",
    "\n",
    "$\\Sigma_{i}^{n}$ is the pbability of event, $\\text{log}_{2}P(x_i)$ represents the amount of information coming from the event.\n",
    "\n",
    "As there is the minus sign, so the lower the entropy, the more information delivered.\n",
    "\n",
    "<img src=\"img/decision_tree_entropy.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To proof this, assumed that there are 2 groups A abd B, obviously can see that A group has higher purity than B.\n",
    "\n",
    "Let's calculate the entropy for these two groups.  \n",
    "  \n",
    "$H_A = \\frac{24}{30}\\text{log}_{2}\\frac{24}{30} + \\frac{6}{30}\\text{log}_{2}\\frac{6}{30}=0.65$\n",
    "  \n",
    "$H_B = \\frac{15}{30}\\text{log}_{2}\\frac{15}{30} + \\frac{15}{30}\\text{log}_{2}\\frac{15}{30}=1$\n",
    "\n",
    "As a result, we need to find a plit can get lower entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X=np.array(iris.data)\n",
    "y = np.array(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(class_probabilitues: list) -> float:\n",
    "    \"\"\"Implement the entropy function\n",
    "    Args:\n",
    "        class_probabilitues (list): A list of class probabilities\n",
    "    Returns:\n",
    "        entropy (float): The entropy of the given class probabilities\"\"\"\n",
    "    return sum([-p * np.log2(p)] for p in class_probabilitues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "def split(X: np.array, y: np.array, feature_idx: int, feature_val: float) -> Tuple[np.array, np.array]:\n",
    "    \"\"\"Split the data into two group with the given feature and value\n",
    "    Args:\n",
    "        X (np.array): The input data\n",
    "        y (np.array): The target labels\n",
    "        feature_idx (int): The index of the feature to split\n",
    "        feature_val (float): The value to split on\n",
    "    Returns:\n",
    "            X_left (np.array): The probability of each class in the left split data\n",
    "            X_right (np.array): The probability of each class in the right split data\"\"\"\n",
    "    g1 = y[X.T[feature_idx]<feature_val]\n",
    "    g2 = y[X.T[feature_idx]>=feature_val]\n",
    "    n_classes = len(np.unique(y))\n",
    "\n",
    "    p1 = [np.sum(g1==c)/len(g1) for c in range(n_classes)]\n",
    "    p2 = [np.sum(g2==c)/len(g2) for c in range(n_classes)]\n",
    "\n",
    "    return p1, p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fin_best_split(X, y):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
